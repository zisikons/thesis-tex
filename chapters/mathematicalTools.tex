\chapter{Μαθηματικά Εργαλεία}

Στο κεφάλαιο αυτό γίνεται εισαγωγή των μαθηματικών εργαλείων και βασικών εννοιών στα οποία βασίζεται η διπλωματική εργασία. Σκοπός του κεφαλαίου είναι η συμφιλίωση του αναγνώστη με αυτές τις έννοιες, έτσι ώστε να γίνει ομαλή η μετάβαση στα αποτελέσματα της διπλωματικής εργασίας στα κεφάλαια που ακολουθούν. 

Συνοπτικά, τρία είναι τα εργαλεία που θα παρουσιαστούν. Αρχικά θα γίνει μια εισαγωγή στα νευρωνικά δίκτυα RBF με έμφαση στην αρχιτεκτονική τους, στον τρόπο που χρησιμοποιούνται στις εφαρμογές αναγνώρισης και ελέγχου, καθώς και τις προσεγγιστικές τους ιδιότητες. Στην συνέχεια θα παρουσιαστεί ο Έλεγχος Προδιαγεγραμμένης Απόκρισης, ο σκοπός που χρησιμοποιείται σε αυτή την εργασία καθώς και επιχειρήματα που αποδεικνύουν την εγκυρότητα του, τόσο σε μαθηματικό επίπεδο όσο και με την χρήση προσομοιώσεων. Τέλος, θα γίνει μια συνοπτική εισαγωγή στην αρχιτεκτονική του υποσυστήματος που παράγει τα σήματα αναφοράς του σχήματος, καθώς και ποιοι είναι οι λόγοι που χρησιμοποιείται αυτή η μεθοδολογία και όχι κάποια άλλη.


%Artificial neural networks (ANNs) or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains.[1] Such systems "learn" (i.e. progressively improve performance on) tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as "cat" or "no cat" and using the results to identify cats in other images. They do this without any a priori knowledge about cats, e.g., that they have fur, tails, whiskers and cat-like faces. Instead, they evolve their own set of relevant characteristics from the learning material that they process.

\section{Νευρωνικά Δίκτυα RBF}
Με τον όρο \textit{Tεχνητά Νευρωνικά Δίκτυα} (Artificial Neural Networks) αναφερόμαστε σε μια κατηγορία μαθηματικών μοντέλων τα οποία προέκυψαν την δεκαετία του 1940 και είναι εμπνευσμένα από τα βιολογικά νευρωνικά δίκτυα τα οποία απαντώνται στους εγκεφάλους των ανθρώπων και των ζώων. Το κύριο χαρακτηριστικό των νευρωνικών δικτύων είναι η εγγενής ικανότητα μάθησης. Ως μάθηση μπορεί να οριστεί η σταδιακή βελτίωση της ικανότητας του δικτύου να επιλύει κάποιο πρόβλημα (π.χ. η σταδιακή προσέγγιση μίας συνάρτησης). Η μάθηση επιτυγχάνεται μέσω της εκπαίδευσης, μίας επαναληπτικής διαδικασίας σταδιακής προσαρμογής των παραμέτρων του δικτύου σε τιμές κατάλληλες ώστε να επιλύεται με επαρκή επιτυχία το προς εξέταση πρόβλημα.


Υπάρχουν πολλές κατηγορίες νευρωνικών δικτύων όπως τα Συνελικτικά Νευρωνικά Δίκτυα (Convolutional Neural Networks), τα Αναδρομικά Νευρωνικά Δίκτυα (Recurrent Neural Networks), τα Ακτινικά Νευρωνικά Δίκτυα (Radial Basis Networks), τα Πιθανοτικά Νευρωνικά Δίκτυα (Probabilistic Neural Networks) και άλλα, κάθε ένα κατάλληλο για διαφορετικό τύπο εφαρμογών. Εμείς θα χρησιμοποιήσουμε τα ακτινικά νευρωνικά δίκτυα τα οποία από εδώ και στο εξής θα αναφέρουμε ως \textit{δίκτυα RBF} καθώς είναι τα καταλληλότερα για προσέγγιση συναρτήσεων.

\subsection{Αρχιτεκτονική}
Η αρχιτεκτονική ενός RBF νευρωνικού δικτύου παρουσιάζεται στο σχήμα $(\ref{fig:rbf_network_architecture})$. Ένα RBF νευρωνικό δίκτυο αποτελείται από τρία επίπεδα, το επίπεδο εισόδου, το ενδιάμεσο ή κρυφό επίπεδο, και το επίπεδο εξόδου.

\begin{figure}
	\centering
	\input{./images/tikz/rbf_network.tex}
	\caption{ Αρχιτεκτονική Νευρωνικού Δικτύου RBF }
	\label{fig:rbf_network_architecture}
\end{figure}

\textbf{Επίπεδο Εισόδου}: Η είσοδος ενός δικτύου RBF είναι ένα διάνυσμα $x = \begin{bmatrix} x_1,x_2, ..., x_n \end{bmatrix}^T$. Στα νευρωνικά δίκτυα αυτής της κατηγορίας το επίπεδο εισόδου είναι υπεύθυνο για την μετάδοση των επιμέρους ορισμάτων $x_i$ σε κάθε νευρώνα και όχι για κάποια περαιτέρω προεπεξεργασία δεδομένων.

\textbf{Κρυφό Επίπεδο:} Στο κρυφό επίπεδο λαμβάνει χώρο ο υπολογισμός των συναρτήσεων $\varphi_i(x)$ οι οποίες ονομάζονται \textit{συναρτήσεις βάσης} ή \textit{συναρτήσεις ενεργοποίησης}. Σε άλλους τύπους δικτύων μπορεί να υπάρχουν πάνω από ένα κρυφά επίπεδα, αλλά στα RBF δίκτυα που μελετάμε υπάρχει μόνο ένα.

Κάθε συνάρτηση βάσης είναι μια πραγματική συνάρτηση $\varphi: \mathbb{R}^n \rightarrow \mathbb{R} $, και αντιστοιχεί σε ένα σημείο του χώρου $c \in \mathbb{R}^n$. Οι συναρτήσεις $\varphi$ είναι ακτινικές συναρτήσεις, που σημαίνει πως το αποτέλεσμα τους εξαρτάται από την απόσταση της εισόδου $x$ από το σημείο $c$, ή αλλιώς μαθηματικά:
\begin{equation*}
	\varphi(x,c) = \varphi(\| x - c \|)
\end{equation*}
και από εκεί προκύπτει και η ονομασία Ακτινικά Νευρωνικά Δίκτυα. Τυπικές ακτινικές συναρτήσεις είναι η γκαουσιανή, η τετραγωνική, η αντίστροφη τετραγωνική και άλλες~\cite{wiki:rbf}, ωστόσο σε αυτήν την εργασία θα χρησιμοποιήσουμε τις γκαουσιανές συναρτήσεις οι οποίες έχουν την μορφή
\begin{equation*}
	\varphi(x) = \exp \left( - \left\| \frac{x - c}{\sigma}\right\|^2 \right)
\end{equation*}
Το σημείο $c$ ονομάζεται \textit{κέντρο} ενώ η ποσότητα $\sigma$ ονομάζεται \textit{διασπορά}. Στην εφαρμογή μας, και τα δυο αυτά μεγέθη επιλέγονται εκ των προτέρων και παραμένουν σταθερά κατά την διάρκεια των πειραμάτων. Ένα παράδειγμα μιας μονοδιάστασης γκαουσιανής συνάρτησης φαίνεται στο σχήμα $(\ref{fig:gaussian_function})$.


\textbf{Επίπεδο Εξόδου:} Η έξοδος ενός RBF νευρωνικού δικτύου είναι μια βαθμωτή συνάρτηση $f: \mathbb{R}^n \rightarrow \mathbb{R} $. Η έξοδος αυτή υπολογίζεται στο επίπεδο εξόδου ώς το σταθμισμένο άθροισμα:
\begin{equation*}
	f(x) = \sum_{i = 1}^{N} w_i \varphi_i (x)
\end{equation*}
Τα βάρη $w_i$ ονομάζονται \textit{συναπτικά βάρη}, και αποτελούν τις ελεύθερες παραμέτρους του δικτύου. Καθώς οι συναρτήσεις βάσης $\varphi_i(x)$ είναι προεπιλεγμένες και σταθερές, λέμε ότι το μοντέλο είναι \textit{γραμμικά παραμετροποιημένο} που θα πει ότι η έξοδος του είναι γραμμικός συνδυασμός των ελεύθερων παραμέτρων αυτού. Τέλος, η έξοδος του μοντέλου μπορεί να γραφτεί και διανυσματικά ώς:
\begin{equation*}
	f(x) = \begin{bmatrix} w_1 & w_2 & ... & w_n \end{bmatrix} \cdot \begin{bmatrix}
	\varphi_1(x) \\ \varphi_2(x) \\ ... \\ \varphi_n(x)
	\end{bmatrix} = 
	W^T \cdot  \varPhi(x)
\end{equation*}
Το διάνυσμα $W$ ονομάζεται \textit{διάνυσμα βαρών} ενώ το διάνυσμα $\varPhi(x)$ ονομάζεται \textit{διάνυσμα οπισθοδρομητών} στην βιβλιογραφία της αναγνώρισης συστημάτων. Η γραμμικότητα ως προς τις ελεύθερες παραμέτρους αποτελεί σημαντικό πλεονέκτημα στα προβλήματα αναγνώρισης, για αυτό και τα γραμμικά παραμετροποίημενα μοντέλα προτιμούνται σε τέτοιου είδους εφαρμογές.

\begin{figure}
	\centering
	\scalebox{.5}{\input{plots/mathematicalTools/networks/simple_gaussian.tex}}
	\caption{ Γκαουσιανή συνάρτηση ενεργοποίησης. Το κέντρο $c$ είναι το σημείο στο οποίο η συνάρτηση παρουσιάζει την μέγιστη τιμή, ενώ η διασπορά $\sigma$ καθορίζει τον ρυθμό που η συνάρτηση μειώνεται όσο το $x$ απομακρύνεται από το $c$. }
	\label{fig:gaussian_function}
\end{figure}


\begin{figure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[scale=0.5]{plots/mathematicalTools/networks/components.tex}
		\caption{Επιμέρους όροι}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[scale=0.5]{plots/mathematicalTools/networks/f_approximation.tex}
		\caption{Συνολική Προσέγγιση}
	\end{subfigure}
	\caption{ Προσέγγιση της $f(x) = 1+x$ από ένα απλό RBF νευρωνικό δίκτυο. }
	\label{fig:rbf_approximation}
\end{figure}

\subsection{Προσεγγιστικές Ιδιότητες}
Τα ακτινικά νευρωνικά δίκτυα είναι ένα πολύ χρήσιμο εργαλείο στην αναγνώριση μη γραμμικών συστημάτων. Ο λόγος είναι πως η παραπάνω δομή μπορεί να προσεγγίσει ικανοποιητικά καλά μια οποιαδήποτε συνεχή συνάρτηση όπως αναφέρεται στην ακόλουθη ιδιότητα~\cite{park1991universal}.

\textbf{Ιδιότητα Προσέγγισης:} \textit{Για κάθε συνεχή συνάρτηση $f: \mathbb{R}^n \rightarrow \mathbb{R} $ και κάθε θετική σταθερά $\epsilon > 0$ υπάρχουν ακέραιος αριθμός $q$, βέλτιστα βάρη $W^* \in \mathbb{R}^q$ και διανυσματικό πεδίο βάσης $\varPhi: \mathbb{R}^n \rightarrow \mathbb{R}^q$, τέτοια ώστε:
\begin{equation*}
	\max_{x \in \Omega_x} \left\| f(x) - W^{*T}\varPhi(x) \right\| \leq \epsilon
\end{equation*}
όπου $\Omega_x$ είναι ένα συμπαγές σύνολο προσέγγισης.
}

Σύμφωνα με την παραπάνω ιδιότητα αν το μέγεθος του διανυσματικού πεδίου βάσης $q$ είναι αρκούντως μεγάλο και οι συναρτήσεις που περιλαμβάνει είναι κατάλληλα επιλεγμένες τότε υπάρχουν βέλτιστα βάρη $W^*$ τέτοια ώστε η έξοδος του νευρωνικού δικτύου να προσεγγίζει οσοδήποτε καλά την άγνωστη συνάρτηση $f(x)$ μέσα στο σύνολο $\Omega_x$. Ως εκ τούτου, μπορούμε να αντικαταστήσουμε, χωρίς βλάβη γενικότητας, την άγνωστη συνάρτηση $f(x)$ με ένα RBF νευρωνικό δίκτυο ως εξής:
\begin{equation*}
	f(x) = W^{*T}\varPhi(x) + \epsilon_f(x)
\end{equation*}

Η ποσότητα $\epsilon_f(x)$ ονομάζεται \textit{σφάλμα μοντελοποίησης}, και εξαρτάται από την αρχιτεκτονική του νευρωνικού δικτύου, δηλαδή το πλήθος και την διάταξη των συναρτήσεων βάσης και αντίστοιχα των κέντρων και των διασπορών του νευρωνικού δικτύου.

\textbf{Παράδειγμα}\\
Στο παράδειγμα που ακολουθεί, θα γίνει μια επίδειξη των προσεγγιστικών ικανοτήτων ενός RBF νευρωνικού δικτύου. Για λόγους απλότητας θα προσεγγίσουμε την μονοδιάστατη συνάρτηση $f: \mathbb{R} \rightarrow \mathbb{R} $
\begin{equation*}
f(x) = 1+x
\end{equation*}
στο συμπαγές σύνολο $\Omega_x = [-1,1] \subset \mathbb{R}$. Για την προσέγγιση θα χρησιμοποιήσουμε ένα νευρωνικό δίκτυο RBF με τρία κέντρα κατανεμημένα στο $\Omega_x$. Τα κέντρα αυτά θα είναι τα $c = \begin{bmatrix} -0.7 & 0.0 & 0.7 \end{bmatrix}$ και η διασπορά $\sigma$ είναι $0.4$. 

{
\begin{wrapfigure}{r}{0.4\textwidth}
	\centering
	\includegraphics[scale=0.5]{plots/mathematicalTools/networks/f_approximation_dense.tex}
	\caption{Προσέγγιση με πυκνότερο δίκτυο}
	\label{fig:rbf_dense_approximation}	
\end{wrapfigure}

Τα αποτελέσματα της προσέγγισης φαίνονται στο σχήμα $(\ref{fig:rbf_approximation})$. Αρχικά στο σχήμα $(\ref{fig:rbf_approximation}.a)$ φαίνονται τα βέλτιστα βάρη για κάθε μια από τις συναρτήσεις βάσης, και το άθροισμα τους το οποίο αποτελεί την προσέγγιση $\hat{f}(x)$ φαίνεται στο σχήμα $(\ref{fig:rbf_approximation}.b)$. 

Όπως φαίνεται λοιπόν από το σχήμα $(\ref{fig:rbf_approximation}.b)$, το εκπαιδευμένο νευρωνικό δίκτυο καταφέρνει να προσεγγίσει ικανοποιητικά την άγνωστη συνάρτηση στην περιοχή ενδιαφέροντος $\Omega_x$. Το σφάλμα μοντελοποίησης $\epsilon_f(x)$ είναι η σκιαγραφημένη περιοχή, ενώ στο σχήμα φαίνεται και το μέγιστο σφάλμα $\epsilon$. Καθώς αυτό το σφάλμα είναι το ελάχιστο δυνατό για την δεδομένη αρχιτεκτονική που έχουμε επιλέξει, στην περίπτωση που απαιτείται μεγαλύτερη ακρίβεια, πρέπει να αυξήσουμε τον αριθμό των συναρτήσεων βάσης. Μια προσέγγιση με την χρήση ενός πυκνότερου δικτύου φαίνεται στο σχήμα $(\ref{fig:rbf_dense_approximation})$

}

Τέλος, είναι σημαντικό να σημειωθεί πως το θεώρημα μας εξασφαλίζει πως το σφάλμα $\epsilon_f(x)$ φράσσεται από το $\epsilon$ μόνο εντός του $\Omega_x$. Όπως φαίνεται και στο σχήμα $(\ref{fig:rbf_approximation}.b)$, όσο απομακρυνόμαστε από το $\Omega_x$ το σφάλμα μεγαλώνει ανεξέλεγκτα.


\section{Συνθήκη Επιμένουσας Διέγερσης}
Όπως είδαμε στο κεφάλαιο $2.1$, μπορούμε να χρησιμοποιήσουμε το μαθηματικό μοντέλο των νευρωνικών δικτύων $RBF$ για να προσεγγίσουμε αρκούντως καλά μια συνεχή μη-γραμμική συνάρτηση σε ένα πεδίο ενδιαφέροντος $\Omega_x$. Πώς όμως εξασφαλίζεται ότι τα βάρη $W$ θα συγκλίνουν στα βέλτιστα βάρη $W^*$ κατά την εκτίμηση παραμέτρων;

Η απάντηση στο παραπάνω ερώτημα δίνεται από την συνθήκη της επιμένουσας διέγερσης (Persistancy of Excitation Condition), η οποία δίνεται παρακάτω:

\textbf{Συνθήκη Επιμένουσας Διέγερσης:} 
\textit{Έστω $\mu$ ένα θετικό $\Sigma$-πεπερασμένο μέτρο Borel στο διάστημα $[0,\infty)$. Μια συνεχής, ομοιόμορφα φραγμένη διανυσματική συνάρτηση $\varPhi: [0,\infty) \rightarrow \mathbb{R}^q$ ικανοποιεί την συνθήκη Επιμένουσας Διέγερσης εάν υπάρχουν θετικές σταθερές $a_1$, $a_2$ και $T$ έτσι ώστε:
\begin{equation}
	a_1 \left\| W \right\|^2 
	\leq
	\int_{t_0}^{t_0 + T} \left| W^T \varPhi(\tau) \right|^2 d\mu(\tau) 
	\leq
	a_2 \left\| W \right\|^2, \quad
	\forall \: t_0 \geq 0 , \quad
	\forall \: W \in \mathbb{R}^q
	\label{eq:pe_condition}
\end{equation}
}

Διαισθητικά το παραπάνω θεώρημα θα πει πως η συνθήκη επιμένουσας διέγερσης ικανοποιείται όταν η τροχιά του συστήματος εξερευνεί πλήρως τον χώρο ελεύθερων παραμέτρων. Η παρακάτω έννοια θα εξηγηθεί και στην συνέχεια με παραδείγματα.

\textbf{Παρατήρηση 1:} Στην παραπάνω εξίσωση, οι σταθερές $a_1$ και $a_2$ ονομάζονται επίπεδα διέγερσης, και οι τιμές τους είναι καθοριστικές για την απόδοση των αλγορίθμων αναγνώρισης (ρυθμός σύγκλισης, άνω φράγματα σφαλμάτων). Ωστόσο, το παραπάνω Θεώρημα είναι θεώρημα ύπαρξης αυτών των τιμών, και όχι υπολογισμού τους.

\textbf{Παρατήρηση 2:} Ο λόγος που το διάνυσμα οπισθοδρομητών $\varPhi(x)$ εμφανίζεται στην παραπάνω εξίσωση ως συνάρτηση του χρόνου $t$ είναι επειδή στην πράξη, το διάνυσμα καταστάσεων $x(t)$ είναι μια καμπύλη $x: [0,\infty) \rightarrow \mathbb{R}^n$. Η ικανοποίηση της ΣΕΔ στις εφαρμογές \textit{οnline} αναγνώρισης συστημάτων ανάγεται ακριβώς στο πρόβλημα της σχεδίασης ενός ελεγκτή που επιτυγχάνει την παρακολούθηση μιας τροχιάς η οποία διεγείρει επαρκώς την δυναμική συστήματος.

\textbf{Παρατήρηση 3:} Η ισχύς του παραπάνω θεωρήματος είναι γενική και δεν ισχύει μόνο για το μοντέλο των RBF νευρωνικών δικτύων. Εν αντιθέσει, το θεώρημα δεν θέτει κανέναν περιορισμό για την δομή του διανύσματος οπισθοδρομητών $varPhi(\tau)$, συνεπώς οποιαδήποτε επιλογή μοντέλου και σετ δεδομένων $x(t)$ μπορούν να χρησιμοποιηθούν.

\textbf{Παρατήρηση 4:} Είναι σημαντικό να τονίσουμε πως η ΣΕΔ το μόνο που εξασφαλίζει είναι ότι τα βέλτιστα βάρη για το επιλεγμένο μοντέλο μπορούν να βρεθούν. Αυτό δεν συνεπάγεται απαραίτητα ότι το μοντέλο αυτό είναι ικανό να προσεγγίσει επαρκώς την δυναμική του συστήματος (Παράδειγμα 2).

\subsection{Παράδειγμα 1: Μη ικανοποίηση της Σ.Ε.Δ}
Έστω ότι θέλουμε να προσεγγίσουμε την άγνωστη συνάρτηση $f(x) = \sqrt{x}$ στο κλειστό σύνολο $\Omega_x = [0,2]$. Για τον σκοπό αυτό, θα χρησιμοποιήσουμε δυο συναρτήσεις ράμπα τοποθετημένες στο $x=0$ και στο $x=1$. Καθώς η συνάρτηση ράμπα περιγράφεται από τον παρακάτω τύπο
\begin{equation*}
	R_i(x) = \begin{cases}
	x-i \:&, x \geq i\\
	0 \: &, x<i 
	\end{cases}
\end{equation*}
το μαθηματικό μοντέλο που χρησιμοποιούμε είναι το:
\begin{equation}
y = a R_0(x) + b R_1(x)
\label{eq:ramp_model}
\end{equation}
όπου $a$ και $b$ οι ελεύθεροι παράμετροι. Χρησιμοποιώντας αυτό το μοντέλο, η βέλτιστη δυνατή προσέγγιση φαίνεται στο σχήμα $(\ref{fig:sqrt_approximation})$.

\begin{figure}
	\centering
	\scalebox{1}{\input{plots/mathematicalTools/pe/sqrt_approx.tex}}
	\caption{ Προσέγγιση της $\sqrt{x}$ από ράμπες}
	\label{fig:sqrt_approximation}
\end{figure}

\subsubsection{Διαισθητική Ερμηνεία}
Με την φράση \emph{"η τροχιά του συστήματος εξερευνεί πλήρως τον χώρο ελεύθερων παραμέτρων"} εννοούμε πως κατά την διάρκεια συλλογής δεδομένων, ανεξαρτήτως του αν ο αλγόριθμος είναι online ή offline, πρέπει η τροχιά $x(t)$ να διεγείρει όλες τις συνιστώσες του διανύσματος του διανύσματος οπισθοδρομητών.

Στο συγκεκριμένο παράδειγμα, το διάνυσμα οπισθοδρομητών είναι το
\begin{equation*}
	\varPhi(x(t)) = \begin{bmatrix}
	R_0(x(t)) \\ R_1(x(t)) 
	\end{bmatrix}
\end{equation*}
Εάν κατά την διάρκεια εκτέλεσης ενός πειράματος αναγνώρισης, η τροχιά $x(t)$ ανήκει εξολοκλήρου στο σύνολο $\Omega_1$ (σχήμα ...), τότε η εκτίμηση $\hat{f}(x)$ εκφυλίζεται σε:
\begin{equation*}
\begin{split}
\hat{f}(x) &=\begin{bmatrix} a & b \end{bmatrix} 
\begin{bmatrix} R_0(x) \\ R_1(x) \end{bmatrix} \xRightarrow{x \in \Omega_1}\\
&= a R_0(x)
\end{split}
\end{equation*}
και κατά συνέπεια η παράμετρος $b$ δεν επηρεάζει καθόλου το αποτέλεσμα. Συνεπώς, κανένας αλγόριθμος εκτίμησης παραμέτρων δεν μπορεί να εκτιμήσει σωστά αυτή την παράμετρο με αποτέλεσμα την αποτυχία του πειράματος αναγνώρισης.


\begin{figure}
	\centering
	\scalebox{1}{\input{plots/mathematicalTools/pe/regressor_path.tex}}
	\caption{ Γεωμετρικός τόπος του $\varPhi(x)$ στο $\Omega$}
	\label{fig:regressor_locus}
\end{figure}

\subsubsection{Μαθηματική Απόδειξη}
Αρχικά, ας εξετάσουμε την σχέση $(\ref{eq:pe_condition})$. Χρησιμοποιώντας τον γεωμετρικό ορισμό του εσωτερικού γινομένου για τον όρο $W^T \varPhi(x(t))$ έχουμε
\begin{equation*}
\begin{split}
a_1 \left\| W \right\|^2  &\leq
\int_{t_0}^{t_0 + T} \left| W^T \varPhi(\tau) \right|^2 d\mu(\tau) 
\leq
a_2 \left\| W \right\|^2
\xRightarrow{a^T \cdot b = \| a\| \|b \| \cos{\theta}}\\
% Second Line
a_1  \cancel{\left\| W \right\|^2} &\leq % left
\cancel{\left\| W \right\|^2}  
\int_{t_0}^{t_0 + T} \left\| \varPhi(\tau) \right\|^2 \cos^2(\theta) d\mu(\tau) \leq % middle
a_2 \cancel{\left\| W \right\|^2} \Rightarrow \\ %right
a_1 &\leq
\int_{t_0}^{t_0 + T} \left\| \varPhi(\tau) \right\|^2 \cos^2(\theta) d\mu(\tau)
\leq a_2, \quad \text{όπου} \: \theta = \angle (W, \varPhi(\tau))
\end{split}
\end{equation*}
Καθώς το διάνυσμα $W \in \mathbb{R}^q$, η γωνία $\theta$ της παραπάνω εξίσωσης πρακτικά είναι η γωνία του διανύσματος οπισθοδρομητών $\varPhi(x(t))$ με οποιοδήποτε μοναδιαίο διάνυσμα $c$ στον χώρο $\mathbb{R}^q$. Συνεπώς, η παραπάνω σχέση γράφεται αλλιώς και ως:
\begin{equation}
	a_1 \leq \int_{t_0}^{t_0 + T} \left\| c^T \varPhi(\tau) \right\|^2 d\mu(\tau)
	\leq a_2, \quad
	\forall \: t_0 \geq 0 , \quad
	\| c \| = 1
	\label{eq:pe_alternative}
\end{equation}
για κάθε μοναδιαίο διάνυσμα του χώρου $\mathbb{R}^q$. Η εξίσωση $(\ref{eq:pe_alternative})$ αποτελεί μια ισοδύναμη έκφραση της Συνθήκης επιμένουσας διέγερσης, η οποία σε αυτό το παράδειγμα διευκολύνει την ανάλυση.

Επιστρέφοντας στο παράδειγμα μας, έστω ότι έχουμε βρει έναν μηχανισμό ελέγχου που εξαναγκάζει την τροχιά $x(t)$ του συστήματος να εκτελέσει την περιοδική κίνηση
\begin{equation*}
x(t) = 0.5(1+\cos(t))
\end{equation*}
, συνεπώς $ 0 \leq x(t) \leq 1$ άρα $x(t) \in \Omega_1$.

Καθώς η συνάρτηση $x(t)$ είναι περιοδική με περίοδο $2\pi$, έτσι και η συνάρτηση $c^T \varPhi(x(t))$ της εξίσωσης $(\ref{eq:pe_alternative})$, ως σύνθεση με περιοδική συνάρτηση είναι επίσης περιοδική. Έτσι, επιλέγοντας στο θεώρημα ... την σταθερά $T$ ίση με την περίοδο, μπορούμε να χρησιμοποιήσουμε την παρακάτω ιδιότητα των περιοδικών συναρτήσεων:
\begin{equation*}
	\int_{a}^{a+T} f(x) dx = \int_{0}^{T} f(x) dx
\end{equation*}
για να απλοποιήσουμε περαιτέρω το ολοκλήρωμα της ΣΕΔ ως εξής:
\begin{equation*}
\int_{t_0}^{t_0 + T} \left| c^T \varPhi(x(\tau)) \right|^2 d\tau = 
\int_{0}^{T} \left| c^T \varPhi(x(\tau)) \right|^2 d\tau, \quad \forall t_0
\end{equation*}
Από την παραπάνω σχέση, είναι ευκολότερο να αντιληφθεί κανείς την φυσική σημασία της ΣΕΔ. Πρέπει, κατά μήκος μιας περιόδου το διάνυσμα $\varPhi(x(t))$ να εξερευνεί κάθε κατεύθυνση $c$ του χώρου ελεύθερων παραμέτρων. Όσο πιο αποτελεσματική είναι η διέγερση αυτή, τότε τόσο αυξάνεται το κάτω φράγμα $a_1$ το οποίο ονομάζεται και \textit{επίπεδο διέγερσης}.

Για να επιδείξουμε το παραπάνω συμπέρασμα, στο σχήμα $(\ref{fig:regressor_locus})$ μελετάμε την γεωμετρική συμπεριφορά του διανύσματος $\varPhi(x(t))$ συναρτήσει της τροχιάς $x(t)$. Καθότι έχουμε συναρτήσεις ράμπας, το διάνυσμα γράφεται ώς:
\begin{equation*}
	\varPhi(x) = 
	\begin{cases}
	[x, 0]^T    &, \: x \in \Omega_1\\
	[x,x-1]^T &, \: x \in \Omega_2\\
	\end{cases}
\end{equation*}
Όταν η τροχιά $x(t) \in \Omega_1$, τότε το διάνυσμα $\varPhi$ κινείται πάνω στο πορτοκαλί ευθύγραμμο τμήμα. Σε αυτή την περίπτωση όμως, είναι πάντα κάθετο στο μοναδιαίο διάνυσμα $c = [ 1 \: 0 ]^T$, συνεπώς το εσωτερικό γινόμενο $c^T \varPhi(x(\tau))$ είναι $0$ καθ'όλη την διάρκεια της περιόδου. 

Μέσω αυτού του αντιπαραδείγματος βλέπουμε πως δεν υπάρχει θετικό $a_1$ που να ικανοποιεί την παρακάτω σχέση.
\begin{equation*}
	0 < a_1 \leq \int_{0}^{T} \left| c^T \varPhi(x(\tau)) \right|^2 d\tau \quad
	\forall c \in
	\{c \mid c \in \mathbb{R}^2, \: \|c\| =1 \}
\end{equation*}
συνεπώς η διανυσματική συνάρτηση $\varPhi$ δεν ικανοποιεί την συνθήκη επιμένουσας διέγερσης.

Αντιθέτως, μέσω του σχήματος $(\ref{fig:regressor_locus})$ βλέπουμε πως εάν επιλέξουμε μια τροχιά $x(t)$ που να επισκέπτεται και τα δύο σύνολα $\Omega_1$ και $\Omega_2$, τότε το διάνυσμα $\varPhi$ κινείται πάνω στα δύο ευθύγραμμα τμήματα (πορτοκαλί και μπλέ). Σε αυτή την περίπτωση δεν υπάρχει διάνυσμα $c$ του μοναδιαίου κύκλου που να είναι κάθετο σε όλη την διάρκεια της περιόδου $T$, συνεπώς ικανοποιείται η συνθήκη επιμένουσας διέγερσης.

Παρόλα αυτά, ακόμα και σε αυτό το απλό παράδειγμα είναι αρκετά δύσκολος ο αναλυτικός υπολογισμός του επιπέδου διέγερσης $a_1$.

\subsection{Παράδειγμα 2: Σ.Ε.Δ και ποιότητα εκτίμησης}
Σε αυτό το δεύτερο παράδειγμα το ζητούμενο μας είναι η προσέγγιση της άγνωστης συνάρτησης $f(x) = 1 + 0.3\cos(5x)$ με την χρήση του μοντέλου
\begin{equation*}
	y = a \cos(x) + b \sin(x)
\end{equation*}

Όπως και πριν, έτσι και εδώ θα υποθέσουμε πως έχουμε βρει έναν μηχανισμό ελέγχου που εξαναγκάζει την τροχιά $x(t)$ του συστήματος να εκτελέσει την κίνηση $x(t) = t$. Παρόλο που η κίνηση δεν είναι περιοδική όπως πριν, αυτό δεν αποτελεί πρόβλημα αφού τόσο η άγνωστη συνάρτηση $f$, όσο και το διάνυσμα οπισθοδρομητών $\varPhi$ είναι περιοδικές συναρτήσεις του χρόνου.

\subsubsection{Μαθηματική Ανάλυση}
Ας εξετάσουμε την ΣΕΔ για το συγκεκριμένο παράδειγμα χρησιμοποιώντας τον ορισμό $(\ref{eq:pe_alternative})$. Ομοίως με πριν, το διάνυσμα οπισθοδρομητών είναι περιοδικό με περίοδο $2\pi$, συνεπώς ο υπολογισμός της ΣΕΔ ανάγεται στην μελέτη του ολοκληρώματος
\begin{equation*}
	\int_{0}^{T} \left| c^T \varPhi(x(\tau)) \right|^2 d\tau
	\forall c \in
	\{c \mid c \in \mathbb{R}^2, \: \|c\| =1 \}
\end{equation*}

Αναλύοντας το εσωτερικό γινόμενο $c^T \varPhi(x(\tau))$ περαιτέρω, προκύπτει
\begin{equation}
\int_{0}^{T} \left| c^T \varPhi(x(\tau)) \right|^2 d\tau = 
\int_{0}^{T} \|c\|^2 \| \varPhi(x(\tau)) \|^2 \cos^2(\theta) d\tau, \quad
\text{όπου} \: \theta = \angle (c, \varPhi(\tau))
%\forall c \in
%\{c \mid c \in \mathbb{R}^2, \: \|c\| =1 \}
\label{eq:pe_sines}
\end{equation}
Καθώς όμως, το $c$ είναι μοναδιαίο, το μέτρο του είναι $1$. Επίσης, το διάνυσμα οπισθοδρομητών είναι το
\begin{equation*}
	\varPhi(x) = \begin{bmatrix} \cos(x) \\ \sin(x) \end{bmatrix}
\end{equation*}
το μέτρο  $\| \varPhi(x(\tau)) \|$ είναι επίσης $1$ για κάθε $x$. Συνεπώς το ολοκλήρωμα της σχέσης $(\ref{eq:pe_sines})$ απλοποιείται ακόμα περισσότερο και τελικά καταλήγουμε στην τελική μορφή:
\begin{equation*}
	\int_{0}^{T}\cos^2(\theta(t)) d\tau
\end{equation*}
{
\begin{wrapfigure}{r}{0.4\textwidth}
	\centering
	\includegraphics[scale=0.8]{plots/mathematicalTools/pe/regressors_sine.tex}
	\caption{}
	\label{fig:regressors_theta}	
\end{wrapfigure}
όπου η γωνία $\theta(t)$ δίνεται από την σχέση
\begin{equation*}
	\theta(t) = \theta_{\varPhi}(t) - \theta_c ,
	\quad \theta_c \in [0,2\pi]
\end{equation*}
με τα $\theta_{\varPhi}$ και $\theta_c$ να φαίνονται στο σχήμα $(\ref{fig:regressors_theta})$. Λόγω της συμμετρίας του σχήματος, το αποτέλεσμα θα είναι το ίδιο για κάθε γωνία $\theta_c$, και συνεπώς η αριθμητική τιμή του ολοκληρώματος της ΣΕΔ είναι τελικά
\begin{equation*}
\int_{0}^{2\pi}\cos^2(\tau) d\tau = \pi = a_1 = a_2
\end{equation*}

Όπως μπορούμε να δούμε η απλότητα του παραδείγματος μας επιτρέπει τον ακριβή υπολογισμό των επιπέδων διέγερσης και ως εκ τούτου την μαθηματική επαλήθευση της ΣΕΔ.

}

Παρόλα αυτά, χρησιμοποιώντας το παραπάνω μοντέλο για να προσεγγίσουμε την άγνωστη $f(x)$ στο πεδίο ενδιαφέροντος, καταλήγουμε στην προσέγγιση του σχήματος $(\ref{fig:sines_approximation})$ η οποία δεν είναι ιδιαίτερα ικανοποιητική.

\begin{figure}[h!]
\centering
\scalebox{.6}{\input{plots/mathematicalTools/pe/sines_approximation.tex}}
\caption{ Προσέγγιση της $f(x)$ του Παραδείγματος $2$. }
\label{fig:sines_approximation}
\end{figure}

\pagebreak
Το συμπέρασμα που προσπαθούμε να καταλήξουμε μέσω αυτού του παραδείγματος είναι πως ακόμα και αν η ΣΕΔ ικανοποιείται, αυτό δεν συνεπάγεται υποχρεωτικά στην επιτυχία της εφαρμογής αναγνώρισης. Πρέπει και το μοντέλο που χρησιμοποιείται να είναι ικανό να προσεγγίσει την ικανοποιητικά την άγνωστη συνάρτηση.

\subsection{ΣΕΔ για RBF νευρωνικά δίκτυα}
Όπως είδαμε, η μαθηματική εξασφάλιση της ικανοποίησης της Συνθήκης Επιμένουσας Διέγερσης είναι αρκετά πολύπλοκη, ακόμα και σε πολύ απλές εφαρμογές όπως αυτές των Παραδειγμάτων $1$ και $2$. 

Καθώς στην εργασία αυτή χρησιμοποιούμε ως μοντέλα τα RBF νευρωνικά δίκτυα, σε αυτό το κεφάλαιο παρουσιάζουμε ένα αποτέλεσμα που μας επιτρέπει να εγγυηθούμε την ικανοποίηση της ΣΕΔ σε ένα τόσο σύνθετο πρόβλημα.

\textbf{Θεώρημα:} Έστω το σύνολο $I = [t_0, t_0 + T]$, όπου $t_0$ και $T$
θετικές σταθερές, και τα σύνολα $I_i = \{ t \in I :  \| x(t) - c_i \| \} \leq \epsilon, \: i = 1,\dots, q $ με το $\epsilon \leq \frac{1}{2} \min_{i \neq j} \{\| c_i - c_j \| \}$. Εάν υπάρχει σταθερά $T$ έτσι ώστε τα μέτρα $\mu(I_i)$ να είναι κάτω φραγμένο από μια σταθερά $\tau_0$ που είναι ανεξάρτητη του $t_0$ και του $i$, τότε το διάνυσμα οπισθοδρομητών $\varPhi(x(t))$ ικανοποιεί την συνθήκη επιμένουσας διέγερσης της εξίσωσης $(\ref{eq:pe_condition})$.

\subsubsection{Φυσική Σημασία}
Η ερμηνεία του παραπάνω θεωρήματος είναι η εξής: Εάν εντός μιας περιόδου $T$, για κάθε κέντρο $c_i$ υπάρχει ένα χρονικό διάστημα $I_i$ στο οποίο η τροχιά $x(t)$ διέρχεται αρκούντως κοντά από αυτό, και ο χρόνος $\mu (I_i)$ που παραμένει αρκούντως κοντά είναι πάντα μεγαλύτερος από μια σταθερά $\tau_0$, τότε το διανυσματικό πεδίο $\varPhi(x(t))$ ικανοποιεί την ΣΕΔ της εξίσωσης $(\ref{eq:pe_condition})$.

Με αυτόν τον τρόπο, κάθε συνάρτηση ενεργοποίησης $\varphi_i(x(t))$ φτάνει κοντά στην μέγιστη τιμή της τουλάχιστον μια φορά εντός κάθε περιόδου, διεγείροντας έτσι την αντίστοιχη μοναδιαία κατεύθυνση $c$ του χώρου ελεύθερων παραμέτρων $\mathbb{R}^q$.

ίσως μπορώ να βαλω ενα σχήμα εδω... (will see)

\section{Έλεγχος Προδιαγεγραμμένης Απόκρισης}
Ο Έλεγχος Προδιαγεγραμμένης Απόκρισης (Prescribed Performance Control) είναι μια μεθοδολογία ελέγχου που μας επιτρέπει να ελέγξουμε ένα συνεχές δυναμικό σύστημα, εφόσον αυτό ικανοποιεί κάποιες συνθήκες που θα διατυπωθούν παρακάτω. Το μεγάλο πλεονέκτημα αυτής της μεθοδολογίας είναι ότι εγγυάται πως το σφάλμα παρακολούθησης εξόδου θα συγκλίνει σε μια προαποφασισμένη και οσοδήποτε μικρή περιοχή του μηδενός με προεπιλεγμένη ταχύτητα και υπερύψωση.

Ο έλεγχος Προδιαγεγραμμένης Απόκρισης εισήχθη στην εργασία [] το 2008, και τα τελευταία χρόνια έχει αναπτυχθεί εκτεταμένα. Παρόλο που στις εργασίες αυτές έχουν αναπτυχθεί πολλές παραλλαγές που να εξασφαλίζουν προδιαγεγραμένη απόκριση εξόδου σε strict feedback συστήματα, pure feedback συστήματα και άλλα, σε αυτό το κεφάλαιο θα εστιάσουμε την βασική ιδέα της μεθόδου, καθώς και σε έναν συγκεκριμένο τρόπο εφαρμογής του που να εξυπηρετεί τις ανάγκες του προβλήματος μας.

Ενώ υπάρχουν πολλές παραλλαγές του, κάθε μια από τις οποίες είναι σχεδιασμένη για διαφορετικά σενάρια ελέγχου