\chapter{Μαθηματικά Εργαλεία}

Στο κεφάλαιο αυτό γίνεται εισαγωγή των μαθηματικών εργαλείων και βασικών εννοιών στα οποία βασίζεται η διπλωματική εργασία. Σκοπός του κεφαλαίου είναι η συμφιλίωση του αναγνώστη με αυτές τις έννοιες, έτσι ώστε να γίνει ομαλή η μετάβαση στα αποτελέσματα της διπλωματικής εργασίας στα κεφάλαια που ακολουθούν. 

Συνοπτικά, τρία είναι τα εργαλεία που θα παρουσιαστούν. Αρχικά θα γίνει μια εισαγωγή στα νευρωνικά δίκτυα RBF με έμφαση στην αρχιτεκτονική τους, στον τρόπο που χρησιμοποιούνται στις εφαρμογές αναγνώρισης και ελέγχου, καθώς και τις προσεγγιστικές τους ιδιότητες. Στην συνέχεια θα παρουσιαστεί ο Έλεγχος Προδιαγεγραμμένης Απόκρισης, ο σκοπός που χρησιμοποιείται σε αυτή την εργασία καθώς και επιχειρήματα που αποδεικνύουν την εγκυρότητα του, τόσο σε μαθηματικό επίπεδο όσο και με την χρήση προσομοιώσεων. Τέλος, θα γίνει μια συνοπτική εισαγωγή στην αρχιτεκτονική του υποσυστήματος που παράγει τα σήματα αναφοράς του σχήματος, καθώς και ποιοι είναι οι λόγοι που χρησιμοποιείται αυτή η μεθοδολογία και όχι κάποια άλλη.


%Artificial neural networks (ANNs) or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains.[1] Such systems "learn" (i.e. progressively improve performance on) tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as "cat" or "no cat" and using the results to identify cats in other images. They do this without any a priori knowledge about cats, e.g., that they have fur, tails, whiskers and cat-like faces. Instead, they evolve their own set of relevant characteristics from the learning material that they process.

\section{Νευρωνικά Δίκτυα RBF}
Με τον όρο \textit{Tεχνητά Νευρωνικά Δίκτυα} (Artificial Neural Networks) αναφερόμαστε σε μια κατηγορία μαθηματικών μοντέλων τα οποία προέκυψαν την δεκαετία του 1940 και είναι εμπνευσμένα από τα βιολογικά νευρωνικά δίκτυα τα οποία απαντώνται στους εγκεφάλους των ανθρώπων και των ζώων. Το κύριο χαρακτηριστικό των νευρωνικών δικτύων είναι η εγγενής ικανότητα μάθησης. Ως μάθηση μπορεί να οριστεί η σταδιακή βελτίωση της ικανότητας του δικτύου να επιλύει κάποιο πρόβλημα (π.χ. η σταδιακή προσέγγιση μίας συνάρτησης). Η μάθηση επιτυγχάνεται μέσω της εκπαίδευσης, μίας επαναληπτικής διαδικασίας σταδιακής προσαρμογής των παραμέτρων του δικτύου σε τιμές κατάλληλες ώστε να επιλύεται με επαρκή επιτυχία το προς εξέταση πρόβλημα.


Υπάρχουν πολλές κατηγορίες νευρωνικών δικτύων όπως τα Συνελικτικά Νευρωνικά Δίκτυα (Convolutional Neural Networks), τα Αναδρομικά Νευρωνικά Δίκτυα (Recurrent Neural Networks), τα Ακτινικά Νευρωνικά Δίκτυα (Radial Basis Networks), τα Πιθανοτικά Νευρωνικά Δίκτυα (Probabilistic Neural Networks) και άλλα, κάθε ένα κατάλληλο για διαφορετικό τύπο εφαρμογών. Εμείς θα χρησιμοποιήσουμε τα ακτινικά νευρωνικά δίκτυα τα οποία από εδώ και στο εξής θα αναφέρουμε ως \textit{δίκτυα RBF} καθώς είναι τα καταλληλότερα για προσέγγιση συναρτήσεων.

\subsection{Αρχιτεκτονική}
Η αρχιτεκτονική ενός RBF νευρωνικού δικτύου παρουσιάζεται στο σχήμα $(\ref{fig:rbf_network_architecture})$. Ένα RBF νευρωνικό δίκτυο αποτελείται από τρία επίπεδα, το επίπεδο εισόδου, το ενδιάμεσο ή κρυφό επίπεδο, και το επίπεδο εξόδου.

\begin{figure}
	\centering
	\input{./images/tikz/rbf_network.tex}
	\caption{ Αρχιτεκτονική Νευρωνικού Δικτύου RBF }
	\label{fig:rbf_network_architecture}
\end{figure}

\textbf{Επίπεδο Εισόδου}: Η είσοδος ενός δικτύου RBF είναι ένα διάνυσμα $x = \begin{bmatrix} x_1,x_2, ..., x_n \end{bmatrix}^T$. Στα νευρωνικά δίκυτα αυτής της κατηγορίας το επίπεδο εισόδου είναι υπεύθυνο για την μετάδοση των επιμέρους ορισμάτων $x_i$ σε κάθε νευρώνα και όχι για κάποια περαιτέρω προεπεξεργασία δεδομένων.

\textbf{Κρυφό Επίπεδο:} Στο κρυφό επίπεδο λαμβάνει χώρο ο υπολογισμός των συναρτήσεων $\varphi_i(x)$ οι οποίες ονομάζονται \textit{συναρτήσεις βάσης} ή \textit{συναρτήσεις ενεργοποίησης}. Σε άλλους τύπους δικτύων μπορεί να υπάρχουν πάνω από ένα κρυφά επίπεδα, αλλά στα RBF δίκτυα που μελετάμε υπάρχει μόνο ένα.

Κάθε συνάρτηση βάσης είναι μια πραγματική συνάρτηση $\varphi: \mathbb{R}^n \rightarrow \mathbb{R} $, και αντιστοιχεί σε ένα σημείο του χώρου $c \in \mathbb{R}^n$. Οι συναρτήσεις $\varphi$ είναι ακτινικές συναρτήσεις, που σημαίνει πως αποτέλεσμα τους εξαρτάται από την απόσταση της εισόδου $x$ από το σημείο $c$, ή αλλιώς μαθηματικά:
\begin{equation*}
	\varphi(x,c) = \varphi(\| x - c \|)
\end{equation*}
και από εκεί προκύπτει και η ονομασία Ακτινικά Νευρωνικά Δίκτυα. Τυπικές ακτινικές συναρτήσεις είναι η γκαουσιανή, η τετραγωνική, η αντίστροφη τετραγωνική και άλλες~\cite{wiki:rbf}, ωστόσο σε αυτήν την εργασία θα χρησιμοποιήσουμε τις γκαουσιανές συναρτήσεις οι οποίες έχουν την μορφή
\begin{equation*}
	\varphi(x) = \exp \left( - \left\| \frac{x - c}{\sigma}\right\|^2 \right)
\end{equation*}
Το σημείο $c$ ονομάζεται \textit{κέντρο} ενώ η ποσότητα $\sigma$ ονομάζεται \textit{διασπορά}. Στην εφαρμογή μας, και τα δυο αυτά μεγέθη επιλέγονται εκ των προτέρων και παραμένουν σταθερά κατά την διάρκεια των πειραμάτων. Ένα παράδειγμα μιας μονοδιάστασης γκαουσιανής συνάρτησης φαίνεται στο σχήμα --todo-=


\textbf{Επίπεδο Εξόδου:} Η έξοδος ενός RBF νευρωνικού δικτύου είναι μια βαθμωτή συνάρτηση $f: \mathbb{R}^n \rightarrow \mathbb{R} $. Η έξοδος αυτή υπολογίζεται στο επίπεδο εξόδου ώς το σταθμισμένο άθροισμα:
\begin{equation*}
	f(x) = \sum_{i = 1}^{N} w_i \varphi_i (x)
\end{equation*}
Τα βάρη $w_i$ ονομάζονται \textit{συναπτικά βάρη}, και αποτελούν τις ελεύθερες παραμέτρους του δικτύου, ενώ οι συναρτήσεις $\varphi_i$ ονομάζονται \textit{συναρτήσεις βάσης} ή \textit{συναρτήσεις ενεργοποίησης}, και στην εφαρμογή μας είναι προεπιλεγμένες και σταθερές.

\textbf{Κρυφό Επίπεδο:} Στο κρυφό επίπεδο, λαμβάνει χώρο ο υπολογισμός των συναρτήσεων βάσης $\varphi_i(x_1,x_2, ..., x_n)$. Ενώ σε άλλες κατηγορίες νευρωνικών δικτύων μπορεί να υπάρχουν πάνω από ένα κρυφά επίπεδα, στα RBF δίκτυα υπάρχει μόνο ένα. Κάθε συνάρτηση βάσης $\varphi_i(x)$ αντιστοιχεί σε ένα κέντρο $c$ το οποίο είναι ίδιας διάστασης με την είσοδο $x$. 

Επίσης, εδώ αξίζει να σημειωθεί πως οι συναρτήσεις ενεργοποίησης στα ακτινικά δίκτυα είναι συναρτήσεις της μορφής:
\begin{equation*}
	\varphi(x) = \varphi(\|x\|)
\end{equation*}

\begin{figure}
	\centering
	
	
	\scalebox{.5}{\input{plots/mathematicalTools/networks/simple_gaussian.tex}}
	\caption{ Γκαουσιανή συνάρτηση ενεργοποίησης }
	\label{fig:gaussian_function}
\end{figure}


